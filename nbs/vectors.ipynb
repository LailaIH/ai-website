{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "04b20fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "CURRENT_DIR = pathlib.Path().resolve()\n",
    "EXPORTS_DIR = CURRENT_DIR / 'reviews_dataset' /'exports'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0340ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7edf416a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\hp\\Desktop\\blog\\nbs\\final_ds\\df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1af3d740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rate     label\n",
       "0  A very, very, very slow-moving, aimless movie ...     0  negative\n",
       "1  Not sure who was more lost - the flat characte...     0  negative\n",
       "2  Attempting artiness with black & white and cle...     0  negative\n",
       "3       Very little music or anything to speak of.       0  negative\n",
       "4  The best scene in the movie was when Gerardo i...     1  positive"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2344500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['label'].tolist() #['negative','positive','negative',...]\n",
    "texts = df['review'].tolist() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b657f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_legend = {\"positive\":1 , \"negative\":0}\n",
    "labels_as_int = [label_legend[x] for x in labels] #[0,0,0,1,..]\n",
    "label_legend_inverted = {f\"{v}\" : k for k,v in label_legend.items()} #{'0':'negative'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df5cdb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd15d5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ...  46   3 251]\n",
      " [  0   0   0 ...   1   8  49]\n",
      " [  0   0   0 ... 121   2 273]\n",
      " ...\n",
      " [  0   0   0 ... 192 103  15]\n",
      " [  0   0   0 ...  65   5   1]\n",
      " [  0   0   0 ...   1 138 173]]\n"
     ]
    }
   ],
   "source": [
    "MAX_NUM_WORDS = 280\n",
    "tokenizer = Tokenizer(num_words= MAX_NUM_WORDS )\n",
    "tokenizer.fit_on_texts(texts)\n",
    "seq = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "\n",
    "MAX_SEQ_LENGTH = 300\n",
    "X = pad_sequences(seq , maxlen = MAX_SEQ_LENGTH)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c0df7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\hp\\desktop\\blog\\lib\\site-packages (1.24.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7bb16c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c7d303b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "label_as_int_array = np.asarray(labels_as_int)\n",
    "y = to_categorical(label_as_int_array)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e2ea896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.2.1-cp310-cp310-win_amd64.whl (8.3 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\hp\\desktop\\blog\\lib\\site-packages (from scikit-learn) (1.24.2)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting scipy>=1.3.2\n",
      "  Using cached scipy-1.10.0-cp310-cp310-win_amd64.whl (42.5 MB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.2.1 scipy-1.10.0 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "702c1b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "945f372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.33 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe52e2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42f29202",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = {\n",
    "    \"X_train\": X_train ,\n",
    "    \"X_test\": X_test ,\n",
    "    \"y_train\": y_train ,\n",
    "    \"y_test\": y_test ,\n",
    "    \"max_words\":MAX_NUM_WORDS,\n",
    "    \"max_seq\": MAX_SEQ_LENGTH ,\n",
    "    \"label_legend\":  label_legend ,\n",
    "    \"label_legend_inverted\" : label_legend_inverted }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b73b5f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_json = tokenizer.to_json()\n",
    "METADATA_EXPORT_PATH = EXPORTS_DIR / 'metadata.pkl'\n",
    "TOKENIZER_EXPORT_PATH  = EXPORTS_DIR / 'tokenizer.json'\n",
    "\n",
    "TOKENIZER_EXPORT_PATH.write_text(tokenizer_json)\n",
    "\n",
    "with open(METADATA_EXPORT_PATH , 'wb') as f :\n",
    "    pickle.dump(training_data , f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5aff20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "542be015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 300, 128)          35840     \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 300, 128)         0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 196)               254800    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 394       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 291,034\n",
      "Trainable params: 291,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NUM_WORDS, embed_dim, input_length=X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "412c7dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "37/37 [==============================] - 87s 2s/step - loss: 0.3651 - accuracy: 0.8207 - val_loss: 0.5702 - val_accuracy: 0.7210\n",
      "Epoch 2/8\n",
      "37/37 [==============================] - 74s 2s/step - loss: 0.5992 - accuracy: 0.7635 - val_loss: 0.5668 - val_accuracy: 0.7036\n",
      "Epoch 3/8\n",
      "37/37 [==============================] - 72s 2s/step - loss: 0.3630 - accuracy: 0.8326 - val_loss: 0.5791 - val_accuracy: 0.7071\n",
      "Epoch 4/8\n",
      "37/37 [==============================] - 57s 2s/step - loss: 0.3238 - accuracy: 0.8497 - val_loss: 0.5960 - val_accuracy: 0.7106\n",
      "Epoch 5/8\n",
      "37/37 [==============================] - 66s 2s/step - loss: 0.3066 - accuracy: 0.8651 - val_loss: 0.6125 - val_accuracy: 0.7331\n",
      "Epoch 6/8\n",
      "37/37 [==============================] - 64s 2s/step - loss: 0.2863 - accuracy: 0.8753 - val_loss: 0.6664 - val_accuracy: 0.7210\n",
      "Epoch 7/8\n",
      "37/37 [==============================] - 64s 2s/step - loss: 0.2909 - accuracy: 0.8625 - val_loss: 0.6288 - val_accuracy: 0.7192\n",
      "Epoch 8/8\n",
      "37/37 [==============================] - 64s 2s/step - loss: 0.2735 - accuracy: 0.8822 - val_loss: 0.7107 - val_accuracy: 0.7279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1857f7cf160>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 8\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, verbose=1, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "62578b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text_str, max_words=280, max_sequence = 300, tokenizer=None):\n",
    "    if not tokenizer:\n",
    "        return None\n",
    "    sequences = tokenizer.texts_to_sequences([text_str])\n",
    "    x_input = pad_sequences(sequences, maxlen=max_sequence)\n",
    "    y_output = model.predict(x_input)\n",
    "    top_y_index = np.argmax(y_output)\n",
    "    preds = y_output[0]\n",
    "  \n",
    "    labeled_preds = [{f\"{label_legend_inverted[str(i)]}\": x} for i, x in enumerate(preds)]\n",
    "    return y_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e6005dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 151ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.9657550e-04, 9.9930346e-01]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"such a nice one\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eed86541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "metadata = {\n",
    "    \"labels_legend_inverted\": label_legend_inverted,\n",
    "    \"legend\": label_legend,\n",
    "    \"max_sequence\":  MAX_SEQ_LENGTH,\n",
    "    \"max_words\": MAX_NUM_WORDS,\n",
    "}\n",
    "\n",
    "METADATA_EXPORT_PATH = EXPORTS_DIR / 'metadata.json'\n",
    "METADATA_EXPORT_PATH.write_text(json.dumps(metadata, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9dc51355",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_EXPORT_PATH = EXPORTS_DIR / 'model.h5'\n",
    "model.save(str(MODEL_EXPORT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8bd275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
